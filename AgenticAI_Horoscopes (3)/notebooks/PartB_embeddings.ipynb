{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:03:25.226291Z",
     "start_time": "2025-11-02T03:03:25.211891Z"
    }
   },
   "cell_type": "markdown",
   "source": "#  Parte B ‚Äî Embeddings con OpenAI",
   "id": "a55694f0a04662"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:03:45.042383Z",
     "start_time": "2025-11-02T03:03:25.259343Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Celda 1 ‚Äî Configuraci√≥n inicial",
   "id": "82cba3bd79f4c382"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-02T03:18:41.542110Z",
     "start_time": "2025-11-02T03:18:41.013009Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# Asegurar directorio ra√≠z\n",
    "os.chdir(Path(__file__).resolve().parents[1] if \"__file__\" in locals() else Path.cwd().parents[0])\n",
    "print(\"üìÇ Directorio actual:\", Path.cwd())\n",
    "\n",
    "# Carpetas base\n",
    "summaries_dir = Path(\"data/summaries\")\n",
    "embeddings_dir = Path(\"data/embeddings\")\n",
    "embeddings_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Modelos a usar\n",
    "models = [\"gpt-4o\", \"gpt-4o-mini\"]\n",
    "\n",
    "# Cliente OpenAI\n",
    "client = OpenAI(api_key=\"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\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Directorio actual: /home/brunoz/Documents/AgenticAI_Horoscopes\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:03:45.166441Z",
     "start_time": "2025-11-02T03:03:45.151566Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Celda 2 ‚Äî Cargar res√∫menes",
   "id": "84d0869ce8449adb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:18:44.869437Z",
     "start_time": "2025-11-02T03:18:44.843329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_summaries(path: Path):\n",
    "    \"\"\"Carga todos los res√∫menes JSON y los organiza en un DataFrame.\"\"\"\n",
    "    data = []\n",
    "    for file in path.glob(\"*.json\"):\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                js = json.load(f)\n",
    "\n",
    "            # 1. Texto a vectorizar\n",
    "            text = js.get(\"final_summary\") or js.get(\"raw\", \"\")\n",
    "            if not text:\n",
    "                continue\n",
    "\n",
    "            # 2. Primero intentamos tomar los metadatos DEL JSON\n",
    "            sign = js.get(\"sign\")\n",
    "            date = js.get(\"date\")\n",
    "            interpreter = js.get(\"interpreter\")\n",
    "\n",
    "            # 3. Si falta algo, lo sacamos del nombre del archivo\n",
    "            #    formato esperado: hola_2025-10-31_aries.json\n",
    "            if not sign or not date or not interpreter:\n",
    "                name = file.stem.split(\"_\")\n",
    "                interpreter = name[0]\n",
    "                date = name[1]\n",
    "                # por si acaso el signo tuviera m√°s de una palabra\n",
    "                sign = \"_\".join(name[2:])\n",
    "\n",
    "            data.append({\n",
    "                \"sign\": str(sign).capitalize(),\n",
    "                \"date\": date,\n",
    "                \"interpreter\": interpreter,\n",
    "                \"text\": text,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error al leer {file.name}: {e}\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# usarla as√≠:\n",
    "df = load_summaries(summaries_dir)\n",
    "print(f\"‚úÖ {len(df)} res√∫menes cargados.\")\n",
    "df.head(5)\n"
   ],
   "id": "2caf9ce0d211e0fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 108 res√∫menes cargados.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "       sign        date interpreter  \\\n",
       "0  Escorpio  2025-10-31    lecturas   \n",
       "1       Leo  2025-10-30    lecturas   \n",
       "2    Cancer  2025-10-31        hola   \n",
       "3  Escorpio  2025-10-29        hola   \n",
       "4     Tauro  2025-10-31   20minutos   \n",
       "\n",
       "                                                text  \n",
       "0  On October 31, 2025, Scorpios are encouraged t...  \n",
       "1  ```json\\n{\\n  \"tone\": \"optimistic\",\\n  \"facets...  \n",
       "2  ```json\\n{\\n  \"tone\": \"optimistic\",\\n  \"facets...  \n",
       "3  ```json\\n{\\n  \"tone\": \"introspective and intui...  \n",
       "4  On this day, Taurus, you'll find joy in your p...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>interpreter</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Escorpio</td>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>lecturas</td>\n",
       "      <td>On October 31, 2025, Scorpios are encouraged t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leo</td>\n",
       "      <td>2025-10-30</td>\n",
       "      <td>lecturas</td>\n",
       "      <td>```json\\n{\\n  \"tone\": \"optimistic\",\\n  \"facets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cancer</td>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>hola</td>\n",
       "      <td>```json\\n{\\n  \"tone\": \"optimistic\",\\n  \"facets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Escorpio</td>\n",
       "      <td>2025-10-29</td>\n",
       "      <td>hola</td>\n",
       "      <td>```json\\n{\\n  \"tone\": \"introspective and intui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tauro</td>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>20minutos</td>\n",
       "      <td>On this day, Taurus, you'll find joy in your p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:03:45.215741Z",
     "start_time": "2025-11-02T03:03:45.201895Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Celda 3 ‚Äî Generar embeddings con OpenAI",
   "id": "d9f74e680d4ca523"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:19:01.873183Z",
     "start_time": "2025-11-02T03:19:01.870644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_embeddings(texts, model):\n",
    "    \"\"\"Genera embeddings usando el modelo especificado.\"\"\"\n",
    "    print(f\"üöÄ Generando embeddings con {model} ({len(texts)} textos)...\")\n",
    "    vectors = []\n",
    "    batch_size = 50  # L√≠mite seguro para evitar rate limit\n",
    "\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        response = client.embeddings.create(model=f\"text-embedding-3-large\", input=batch)\n",
    "        vectors.extend([d.embedding for d in response.data])\n",
    "\n",
    "    print(f\"‚úÖ Embeddings creados ({len(vectors)})\")\n",
    "    return np.array(vectors)\n"
   ],
   "id": "b2dd54f29363bc1d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:03:45.749691Z",
     "start_time": "2025-11-02T03:03:45.729312Z"
    }
   },
   "cell_type": "markdown",
   "source": "## CELDA 4 ‚Äî Generar y guardar embeddings (dos modelos)",
   "id": "8513362465be96c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:19:13.186442Z",
     "start_time": "2025-11-02T03:19:08.389246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embeddings_all = []\n",
    "\n",
    "for model in models:\n",
    "    vectors = generate_embeddings(df[\"text\"].tolist(), model)\n",
    "\n",
    "    npy_path = embeddings_dir / f\"embeddings_{model.replace('-', '_')}.npy\"\n",
    "    np.save(npy_path, vectors)\n",
    "    print(f\"üíæ Guardado: {npy_path}\")\n",
    "\n",
    "    # Guardar tambi√©n en lista JSON\n",
    "    for i, row in df.iterrows():\n",
    "        embeddings_all.append({\n",
    "            \"sign\": row[\"sign\"],\n",
    "            \"date\": row[\"date\"],\n",
    "            \"interpreter\": row[\"interpreter\"],\n",
    "            \"model\": model,\n",
    "            \"embedding_vector\": vectors[i].tolist()\n",
    "        })\n",
    "\n",
    "# Guardado combinado\n",
    "with open(embeddings_dir / \"embeddings_all.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(embeddings_all, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úÖ Archivo combinado guardado en data/embeddings/embeddings_all.json\")\n"
   ],
   "id": "a53a8a3fd9781358",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Generando embeddings con gpt-4o (108 textos)...\n",
      "‚úÖ Embeddings creados (108)\n",
      "üíæ Guardado: data/embeddings/embeddings_gpt_4o.npy\n",
      "üöÄ Generando embeddings con gpt-4o-mini (108 textos)...\n",
      "‚úÖ Embeddings creados (108)\n",
      "üíæ Guardado: data/embeddings/embeddings_gpt_4o_mini.npy\n",
      "‚úÖ Archivo combinado guardado en data/embeddings/embeddings_all.json\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:03:45.950613Z",
     "start_time": "2025-11-02T03:03:45.830267Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Celda 5 ‚Äî Verificar embeddings guardados",
   "id": "f0bc38360643c518"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:21:13.920853Z",
     "start_time": "2025-11-02T03:21:13.851715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargar y verificar\n",
    "check = pd.read_json(\"data/embeddings/embeddings_all.json\")\n",
    "print(check.head(3))\n",
    "print(f\"Total embeddings: {len(check)}\")\n"
   ],
   "id": "3246546ec7e64e61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sign       date interpreter   model  \\\n",
      "0  Escorpio 2025-10-31    lecturas  gpt-4o   \n",
      "1       Leo 2025-10-30    lecturas  gpt-4o   \n",
      "2    Cancer 2025-10-31        hola  gpt-4o   \n",
      "\n",
      "                                    embedding_vector  \n",
      "0  [-0.043936226516962, -0.051031034439802, -0.01...  \n",
      "1  [-0.026828752830624, -0.010034312494099001, -0...  \n",
      "2  [-0.007350745610892001, 0.0041490341536700006,...  \n",
      "Total embeddings: 216\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T03:21:16.220315Z",
     "start_time": "2025-11-02T03:21:15.798193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# python\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "emb_dir = Path(\"data/embeddings\")\n",
    "mini_path = emb_dir / \"embeddings_gpt_4o_mini.npy\"\n",
    "large_path = emb_dir / \"embeddings_gpt_4o.npy\"\n",
    "json_path = emb_dir / \"embeddings_all.json\"\n",
    "\n",
    "if mini_path.exists() and large_path.exists():\n",
    "    emb_mini = np.load(mini_path)\n",
    "    emb_large = np.load(large_path)\n",
    "elif json_path.exists():\n",
    "    df_emb = pd.read_json(json_path)\n",
    "    emb_mini = np.vstack(df_emb[df_emb[\"model\"] == \"gpt-4o-mini\"][\"embedding_vector\"].to_list())\n",
    "    emb_large = np.vstack(df_emb[df_emb[\"model\"] == \"gpt-4o\"][\"embedding_vector\"].to_list())\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Missing embeddings in {emb_dir!s} (expected .npy files or {json_path.name}).\")\n",
    "\n",
    "# Ensure 2D arrays\n",
    "if emb_mini.ndim == 1:\n",
    "    emb_mini = emb_mini.reshape(1, -1)\n",
    "if emb_large.ndim == 1:\n",
    "    emb_large = emb_large.reshape(1, -1)\n",
    "\n",
    "if emb_mini.size == 0 or emb_large.size == 0:\n",
    "    raise ValueError(\"One of the embedding arrays is empty.\")\n",
    "\n",
    "sim_mini = cosine_similarity(emb_mini)\n",
    "sim_large = cosine_similarity(emb_large)\n",
    "\n",
    "print(\"üìà Promedio de similitud interna:\")\n",
    "print(\"GPT-4o-mini:\", np.mean(sim_mini))\n",
    "print(\"GPT-4o:\", np.mean(sim_large))"
   ],
   "id": "2556bf7913f93bc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Promedio de similitud interna:\n",
      "GPT-4o-mini: 0.6189009149285587\n",
      "GPT-4o: 0.6189923510680192\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
